{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#time series\n",
    "import datetime\n",
    "import time\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import requests\n",
    "\n",
    "import sklearn\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "import sklearn.datasets\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "#decision tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "#visualizing tree\n",
    "from IPython.display import Image\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "complete_df = pd.read_csv(\"DataSets/Complete_Data.csv\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "<br>\n",
    "\n",
    "This section will discuss the working of a decision tree in generar.<br><br>\n",
    "The following explanation about the structure of a decision tree is given by Hunt (1962) in one of the earliest papers about decision trees:<br>\n",
    "* Let Dt be the set of training records that reaches a node t. \n",
    "* If Dt contains records that belong to the same class, let that class be called Yt, then t is a leaf node labelled as Yt. \n",
    "* If Dt is an empty set or the attribute values are the same, then t is a leaf node labelled by the default class, Yd (the majority class for the parent Dt). \n",
    "* If Dt contains records that belong to more than one class, use an attribute test (this differs for different data types) to split the data into smaller subsets. \n",
    "* Recursively apply this procedure to each subset.\n",
    "<br><br>\n",
    "Following this algorithm produces a decision tree. <br>\n",
    "A decision tree is a tree-like graph system that is used to learn a classification function which concludes the value of a dependent attribute given the values of the independent input variables\n",
    "\n",
    "# J48 Decision Tree\n",
    "A major task of a decision tree, is determining on which attribute to split next. <br>\n",
    "J48 uses entropy (entropy measures the homogeneity of a node) to decide on which attribute to split next. \n",
    "\n",
    "Formula 1 shows how to calculate the entropy on the dataset.\n",
    "<br><br>\n",
    "1.  Entropy(t)= $\\sum_{j}$ ğ‘(ğ‘—|ğ‘¡) ğ‘™ğ‘œğ‘”2 ğ‘(ğ‘—|ğ‘¡)                 \n",
    "<br><br>\n",
    "Here p(j|t) is the relative frequency of class j at node t. Entropy ranges from 0.0 (where all tuples belong to one class, which implies the most information gain), to 1.0 (the tuples are split evenly between the classes). \n",
    "<br> Once the Entropy for every leaf, coming from a parent node is calculated, the average Entropy gain (information gain) for splitting a certain parent attribute into x amount of leaves, can be calculated with formula 2:\n",
    "<br><br>\n",
    "2. ğºğ´ğ¼ğ‘ğ‘ ğ‘ğ‘™ğ‘–ğ‘¡=Entropy (p) âˆ’ ( $\\sum_{i=1}^k$ ğ‘›ğ‘–/ğ‘› * ğ¸ğ‘›ğ‘¡ğ‘Ÿğ‘œğ‘ğ‘¦(ğ‘–) )      \n",
    "<br><br>\n",
    "Here p is a parent node (that is split into k partitions). <br>\n",
    "ğ‘›ğ‘–/n is the number of tuples in partition i, divided by the total amount of tuples that reached the parent node.\n",
    "<br>However, instead of information gain (Gain split) the current j48 decision tree uses gain ratio. \n",
    "<br>This is a slightly more optimised measure to decide on which attribute to split compared to the standard information gain. \n",
    "<br>This is because it gives a higher entropy to decision trees with a lot of small partitions. \n",
    "<br>In data mining complex trees are often times avoided because attribute splits into a lot of different leaves tend to produce models that overfit. \n",
    "<br>This is because the more complex a model becomes, the smaller the amount of tuples become that reach a specific leaf node. \n",
    "<br>A small amount of tuples per leaf node means that there is a high chance that noise, or just simply variance dominates the classifier.\n",
    "<br>The following formula attempt to solve this problem by calculating the gain ratio instead.\n",
    "<br><br>\n",
    "3. SplitINFO=âˆ’  $\\sum_{i=1}^k$ * ğ‘›ğ‘–/ğ‘› * ğ‘™ğ‘œğ‘”2 * ğ‘›i/ğ‘›\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Price_TO_Category(x): #decision tree can only use categoric value\n",
    "    \"\"\"\n",
    "    transforms dependent variable price/day into 4 equal groups:\n",
    "    1 cheap       price < â‚¬96\n",
    "    2 mid-range   96  < price <= 125\n",
    "    3 expensive   125 < price <= 175\n",
    "    4 overpriced  price > 175\n",
    "    \"\"\"\n",
    "    if  x <=96:\n",
    "        return 1                   #cheap\n",
    "    if  x > 96 and x <= 125:\n",
    "         return 2                  #mid-range\n",
    "    if  x > 125 and x <= 175:\n",
    "         return 3                  #expensive\n",
    "    if x >175:\n",
    "        return 4                   #overpriced\n",
    "    \n",
    "complete_df[\"price\"] = complete_df[\"price\"].apply(Price_TO_Category)\n",
    "\n",
    "\n",
    "def transform_neighbourhood(x):\n",
    "    \"\"\"transforms neighbourhood into 4 categories\n",
    "        Noord = 1\n",
    "        East  = 2\n",
    "        West  = 3\n",
    "        Zuid  = 4\n",
    "     \"\"\"\n",
    "    if  x.__contains__(\"Noord\"):\n",
    "        return 1\n",
    "    if  x.__contains__(\"Oost\"):\n",
    "        return 2\n",
    "    if  x.__contains__(\"Zuid\"):\n",
    "        return 3\n",
    "    if  x.__contains__(\"West\"):\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "    \n",
    "complete_df[\"neighbourhood\"] = complete_df[\"neighbourhood\"].apply(transform_neighbourhood)\n",
    "\n",
    "\n",
    "def transform_room_type(x):\n",
    "    \"\"\"transforms neighbourhood into 4 categories\n",
    "        Noord = 1\n",
    "        East  = 2\n",
    "        West  = 3\n",
    "        Zuid  = 4\n",
    "     \"\"\"\n",
    "    if  x.__contains__(\"Private room\"):\n",
    "        return 1\n",
    "    if  x.__contains__(\"Entire home/apt\"):\n",
    "        return 2\n",
    "    if  x.__contains__(\"Shared room\"):\n",
    "        return 3\n",
    "\n",
    "complete_df[\"room_type\"] = complete_df[\"room_type\"].apply(transform_room_type)\n",
    "\n",
    "\n",
    "def property_type(x):\n",
    "    \"\"\"transforms neighbourhood into 4 categories\n",
    "        Noord = 1\n",
    "        East  = 2\n",
    "        West  = 3\n",
    "        Zuid  = 4\n",
    "     \"\"\"\n",
    "    \n",
    "    #house\n",
    "    if  x.__contains__(\"Townhouse\" or \"houseboat\" or \"house\" or \"Tiny house\" or \"Earth house\" or \"Villa\" or \"Cottage\"):\n",
    "        return 1 \n",
    "    #hotel                \n",
    "    if  x.__contains__(\"Bed and breakfast\" or \"Hostel\" or \"Hotel\" or \"Aparthotel\" or \"Guest suite\" or \"Loft\" or \"Cabin\"):\n",
    "        return 2\n",
    "    #apartment\n",
    "    if  x.__contains__(\"Apartment\"):\n",
    "        return 3\n",
    "    #something else\n",
    "    else: \n",
    "        return 4\n",
    "   \n",
    "complete_df[\"property_type\"] = complete_df[\"property_type\"].apply(property_type)\n",
    "                                                          \n",
    "    \n",
    "def bed_type(x):\n",
    "    \"\"\"transforms neighbourhood into 4 categories\n",
    "        Noord = 1\n",
    "        East  = 2\n",
    "        West  = 3\n",
    "        Zuid  = 4\n",
    "     \"\"\"\n",
    "    if  x.__contains__(\"Real Bed\"):\n",
    "        return 1\n",
    "    if  x.__contains__(\"Futon\"):\n",
    "        return 2\n",
    "    if  x.__contains__(\"Pull-out Sofa\"):\n",
    "        return 3\n",
    "    if  x.__contains__(\"Airbed\"):\n",
    "        return 4\n",
    "    if  x.__contains__(\"Couch\"):\n",
    "        return 5\n",
    "\n",
    "complete_df[\"bed_type\"] = complete_df[\"bed_type\"].apply(bed_type)                                                      \n",
    "                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    5086\n",
       "3    5081\n",
       "1    5019\n",
       "4    4844\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we split into even frequencies so zeroR accuracy would be 25%\n",
    "complete_df[\"price\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#independent var\n",
    "X = complete_df.drop(\"price\",axis=1)\n",
    "\n",
    "#dependent var\n",
    "y = complete_df[\"price\"]\n",
    "\n",
    "#splitting on train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "#instantiating decision tree\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "#fitting tree\n",
    "dtree.fit(X_train,y_train)\n",
    "\n",
    "predictions = dtree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[757 376 259 120]\n",
      " [412 506 405 223]\n",
      " [243 438 478 353]\n",
      " [125 242 355 717]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.50      0.50      1512\n",
      "           2       0.32      0.33      0.33      1546\n",
      "           3       0.32      0.32      0.32      1512\n",
      "           4       0.51      0.50      0.50      1439\n",
      "\n",
      "   micro avg       0.41      0.41      0.41      6009\n",
      "   macro avg       0.41      0.41      0.41      6009\n",
      "weighted avg       0.41      0.41      0.41      6009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[915 331 205  61]\n",
      " [381 575 396 194]\n",
      " [181 451 499 381]\n",
      " [ 59 145 312 923]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.61      0.60      1512\n",
      "           2       0.38      0.37      0.38      1546\n",
      "           3       0.35      0.33      0.34      1512\n",
      "           4       0.59      0.64      0.62      1439\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      6009\n",
      "   macro avg       0.48      0.49      0.48      6009\n",
      "weighted avg       0.48      0.48      0.48      6009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,rfc_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualiazing regular Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['room_type',\n",
       " 'minimum_nights',\n",
       " 'number_of_reviews',\n",
       " 'calculated_host_listings_count',\n",
       " 'availability_365',\n",
       " 'host_since',\n",
       " 'property_type',\n",
       " 'accommodates',\n",
       " 'bedrooms',\n",
       " 'bed_type',\n",
       " 'amenities',\n",
       " 'guests_included',\n",
       " 'maximum_nights',\n",
       " 'review_scores_rating',\n",
       " 'cancellation_policy',\n",
       " 'average_review_other',\n",
       " 'price']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(complete_df.columns[1:])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-27-3cc3d2c3cb6b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-27-3cc3d2c3cb6b>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    export_graphviz(dtree,out_file=dot_data,feature_names=features,filled=True,round)\u001b[0m\n\u001b[1;37m                                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(dtree,out_file=dot_data,feature_names=features,filled=True,round)\n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph[0].create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['room_type',\n",
       " 'minimum_nights',\n",
       " 'number_of_reviews',\n",
       " 'calculated_host_listings_count',\n",
       " 'availability_365',\n",
       " 'host_since',\n",
       " 'property_type',\n",
       " 'accommodates',\n",
       " 'bedrooms',\n",
       " 'bed_type',\n",
       " 'amenities',\n",
       " 'guests_included',\n",
       " 'maximum_nights',\n",
       " 'review_scores_rating',\n",
       " 'cancellation_policy',\n",
       " 'average_review_other',\n",
       " 'price']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot \n",
    "\n",
    "features = list(complete_df.columns[1:])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] \"dot\" not found in path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\PythonGuide\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m                 \u001b[0mworking_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1916\u001b[0m             )\n",
      "\u001b[1;32mD:\\PythonGuide\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     )\n",
      "\u001b[1;32mD:\\PythonGuide\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    768\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    770\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\PythonGuide\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1171\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1172\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1173\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Het systeem kan het opgegeven bestand niet vinden",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-96c260692d17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\PythonGuide\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(f, prog, encoding)\u001b[0m\n\u001b[0;32m   1721\u001b[0m                 \u001b[1;34m\"\"\"Refer to docstring of method `create`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1722\u001b[0m                 return self.create(\n\u001b[1;32m-> 1723\u001b[1;33m                     format=f, prog=prog, encoding=encoding)\n\u001b[0m\u001b[0;32m   1724\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'create_{fmt}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1725\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\PythonGuide\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1920\u001b[0m                 args[1] = '\"{prog}\" not found in path.'.format(\n\u001b[0;32m   1921\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1922\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1924\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path."
     ]
    }
   ],
   "source": [
    "dot_data = StringIO()  \n",
    "export_graphviz(dtree, out_file=dot_data,feature_names=features,filled=True,rounded=True)\n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph[0].create_png())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
