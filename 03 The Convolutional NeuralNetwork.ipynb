{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing which model predicts the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first codeblock tests which configuration of hyperparameters works best (by trying all 27 combinations via 2 epoch)\n",
    "<br><br>\n",
    "The second codeblock tests the optimal hyperparameter combination via 10 epoch\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL Test 01 \n",
    "\n",
    "'''\n",
    "In this model we tested to see what configuration of convolutional_layers/layer_size/dense_layers is best \n",
    "\n",
    "We do this by iterating through 3 lists: dense_layers, layer_sizes, conv_layers\n",
    "We then checked which combination of the above lists resulted in the highest accuracy.\n",
    "\n",
    "This combination of best hyperparemeters:\n",
    "[0 dense layers]\n",
    "[128 layer size]\n",
    "[1 conv layer]\n",
    "was then chosen in the second section of this notebook to run with more epochs.\n",
    "\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pickle\n",
    "import time\n",
    "from keras import backend\n",
    "import datetime\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))\n",
    "\n",
    "\n",
    "X = X/255.0 #normalizing data\n",
    "\n",
    "#Hyperparameters of layers\n",
    "dense_layers = [0,1,2]\n",
    "layer_sizes = [32,64,128]\n",
    "conv_layers =[1,2,3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}=-conv-{}-nodes-{}-dense-{}\".format(conv_layer,layer_size,dense_layer,int(time.time()))\n",
    "            tensorboard = TensorBoard(log_dir=\"C:\\\\logs\\\\{}\".format(NAME))\n",
    "            print(NAME)\n",
    "            \n",
    "            #layer 1\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3,3),input_shape = X.shape[1:]))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            for l in range(conv_layer-1):\n",
    "\n",
    "            ####################################################\n",
    "            #adding 3 extra layers\n",
    "\n",
    "            #layer 2\n",
    "                model.add(Conv2D(layer_size,(3,3)))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            model.add(Flatten())\n",
    "                              \n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation(\"relu\"))\n",
    "  \n",
    "\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(64))\n",
    "            model.add(Activation(\"relu\"))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "            model.compile(loss      = \"binary_crossentropy\",\n",
    "                          optimizer = \"adam\",\n",
    "                          metrics   =[\"accuracy\"])\n",
    "\n",
    "            model.fit(X,y,batch_size=32,epochs =2,validation_split = 0.1,callbacks = [tensorboard]) #pass in 32 photos in each batch a time\n",
    "            backend.clear_session()\n",
    "\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This combination of best hyperparemeters: \n",
    "[1 dense layers] <br>\n",
    "[128 layer size]<br>\n",
    "[1 conv layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL Optimal 02\n",
    "\n",
    "'''\n",
    "Here we test the model and gain around 60-65% validation accuracy\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pickle\n",
    "import time\n",
    "from keras import backend\n",
    "import datetime\n",
    "\n",
    "    \n",
    "#IMPORTING THE NN FROM PICKLE!\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))\n",
    "\n",
    "#NORMALISING THE DATA\n",
    "X = X/255.0 #normalizing data\n",
    "\n",
    "\n",
    "\n",
    "#PICKING THE BEST BEST HYPERPARAMETERS IN TERMS OF AMNT OF LAYERS BASED ON THE PREVIOUS MODEL TEST\n",
    "dense_layers = [1]\n",
    "layer_sizes = [128]\n",
    "conv_layers =[1]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}=-conv-{}-nodes-{}-dense-{}\".format(conv_layer,layer_size,dense_layer,int(time.time()))\n",
    "            tensorboard = TensorBoard(log_dir=\"C:\\\\logs\\\\{}\".format(NAME))\n",
    "            print(NAME)\n",
    "            \n",
    "            #layer 1\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3,3),input_shape = X.shape[1:]))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            for l in range(conv_layer-1):\n",
    "            #layer 2\n",
    "                model.add(Conv2D(layer_size,(3,3)))            \n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            model.add(Flatten())\n",
    "                              \n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(512))\n",
    "                model.add(Activation(\"relu\"))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "            model.compile(loss      = \"binary_crossentropy\",\n",
    "                          optimizer = \"adam\",\n",
    "                          metrics   =[\"accuracy\"])\n",
    "\n",
    "            model.fit(X,y,batch_size=32,epochs =10,validation_split = 0.1,callbacks = [tensorboard]) #pass in 32 photos in each batch a time\n",
    "            \n",
    "  #\n",
    "#training_acc    is calculated based on amnt of correct on training data\n",
    "#validation_loss is calculated based on binary_cross_entropy\n",
    "#val_accuracy   is calculated based on 90% of training set (validation split = 0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "After 10 epochs we found a 0.65% validation accuracy in predicting if the person on the picture was either male/female<br>\n",
    "this means that on new unseen data the model would perform significantly better than the ZeroR (randomly guessing) algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
